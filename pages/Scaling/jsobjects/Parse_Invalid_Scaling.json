{
  "unpublishedCollection": {
    "name": "Parse_Invalid_Scaling",
    "pageId": "Scaling",
    "pluginId": "js-plugin",
    "pluginType": "JS",
    "actions": [],
    "archivedActions": [],
    "body": "export default {\n\tparse_data: async () => {\n       try {\n\n\t\t\t\t\t await Select_IScaling_All.run();\n\t\t\t\t\t const scale_data = Select_IScaling_All.data;\n\t\t\t\t\t await Dockets.run();\n\t\t\t\t\t const docket_set = new Set(Dockets.data.map(item => item.Docket));\n\t\t\t\t\t await Logs.run();\n\t\t\t\t\t const log_set = new Set(Logs.data.map(item => item.Log));\n\t\t\t\t\t await Grade.run();            \n\t\t\t\t\t const grade_set = new Set(Grade.data.map(item => item.Grade));\n\t\t\t\t\t await Lengths.run();\n\t\t\t\t\t const length_set = new Set(Lengths.data.map(item => item.Lengths));\n\t\t\t\t\t await Location.run();\n\t\t\t\t\t const location_set = new Set(Location.data.map(item => item.Location));\n\n\t\t\t\t \tconsole.log(\"starting\");\n\t\t\t\t //console.log(log_set);\n\n            const{\n                del_log,\n                scale,\n            } = scale_data.reduce(\n                (acc, sr) => {\n\t\t\t\t\t\t\t\t\t\tconst logs_to_go = () => acc.del_log.push([sr.Log]);\n                    const valid = () => acc.scale.push([sr.Log, sr.Docket, sr.Grade, sr.Length, sr.Diameter, sr.JAS, sr.Location, sr.Date]);\n\t\t\t\t\t\t\t\t\t//console.log(sr.Log);\n                    if ( ! log_set.has(sr.Log) ) {\n\t\t\t\t\t\t\t\t\t\t\t\tif ( (! location_set.has(sr.Location)) || (sr.Location === 'TEST')) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t//console.log(sr.Location)\n\t\t\t\t\t\t\t\t\t\t\t\t\tlogs_to_go();\n                        } else if (isNaN(sr.Docket)) {\n                        } else if ( ! docket_set.has(parseInt(sr.Docket))) {\n                        } else if ((sr.Diameter < 16) || (sr.Diameter > 48) || isNaN(sr.Diameter)) {\n                        } else if ( ! length_set.has(sr.Length) ) {\n                        } else if ( ! (grade_set.has(sr.Grade)) ) {\n                        } else {\n                            valid();\n\t\t\t\t\t\t\t\t\t\t\t\t\t  //console.log(\"valid\");\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tlogs_to_go()\n                        }\n                    } else {\n                        logs_to_go();\n\t\t\t\t\t\t\t\t\t\t\t  //console.log(\"to be deleted\",sr.Log);\n                    }\n                    return acc;\n                },\n                {\n                    scale: [],\n                    del_log: [],\n                }\n            );\n\n\n            console.log(\"processed\",scale.length,del_log.length);\n\n\t\t\t\t   if (scale.length > 0) {\n\t\t\t\t\t\t const data = scale.map(item => `(${item.map(val => `'${val}'`).join(',')})`).join(',');\n\t\t\t\t\t\t //console.log(data.l);\n\t\t\t\t\t\t Insert_VScaling.run({'data': data})\n\t\t\t\t\t\t\t .then(() => showAlert(\"Found Valid Scaling Entires\",'success'))\n\t\t\t\t\t\t\t .catch(() => showAlert(\"Error inserting Valid\",'error'));\n\t\t\t\t\t }\n\t\t\t\t   if (del_log.length > 0) {\n\t\t\t\t\t\t const idata = del_log.map(val => `'${val}'`).join(',');\n\t\t\t\t\t\t //console.log(idata)\n\t\t\t\t\t\t Delete_Invalid_ScalingRows.run({'data': idata })\n\t\t\t\t\t\t\t .then(() => showAlert(\"Deleted Invalid Scaling Entires\",'success'))\n\t\t\t\t\t\t\t .catch(() => showAlert(\"Error deleteing invalid\",'error'));\n\t\t\t\t\t }\n\t\t\t\t   await VScaling.run();\n\t\t\t\t\t await IScaling.run();\n\t\t\t\t   await RejectScaling.run();\n\t\t\t\t   await Invalid_Dockets.run();\n\t\t\t\t   Count_Scaling.run();\n\t\t\t\t  return('success');\n\n        } catch (error) {\n            showAlert(error,'error')\n        }\n\t}\n}",
    "variables": []
  },
  "id": "Scaling_Parse_Invalid_Scaling",
  "deleted": false,
  "gitSyncId": "62c64eab5a06d81bded2fac9_62d9fbe85a06d81bded2fe16"
}